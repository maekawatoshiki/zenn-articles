---
title: "深層学習モデルの推論ランタイムを0から作った話"
emoji: "🧮"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["onnx", "rust", "深層学習"]
published: false
---

# はじめに

深層学習モデルを動作させるためのソフトウェアは数多くあります。
PyTorch や TensorFlow などのフレームワークはそれ自身がモデルを実行する機能を持っていますし、ONNX Runtime のようにモデルを動作させることに特化したソフトウェアも存在します。

これらのソフトウェアは大抵、Python などから簡単に扱うことができます。
しかしながら、それらがどのように動作しているのか疑問に思うことはないでしょうか。

この記事では、0 から深層学習モデルの推論ランタイム（長いので以下「深層学習ランタイム」）を作った過程で学んだことを、とりとめもなく紹介していきます。
作ったものは以下のリポジトリにあります。
（技術的にはかなり適当なことを書いてしまうかもしれません。）

https://github.com/maekawatoshiki/altius


# 深層学習ランタイムは何をするのか

深層学習ランタイムは、深層学習モデルを動作させるためのソフトウェアです。
もう少し具体的に考えてみると、深層学習ランタイムは「モデル」と「入力データ」を受け取り、「出力データ」を返すソフトウェアだと言えます。（ここでは推論時のみを取り扱います。）

今は機械学習寄りの話をしているため、入力・出力データはテンソルとして表現されていることがほとんどです。
例えば、入力として shape が $1 \times 3 \times 224 \times 224$ の画像、出力として shape が $1 \times 1000$ のクラス分類、などが挙げられます。
（ここでは、テンソルは単に多次元配列だと捉えていただければ大丈夫です。流石に適当すぎるかもしれないですが。）

テンソルを受け取り、モデルの構造に沿って何らかの計算を行い、テンソルを返す。この一連の処理を行うのが深層学習ランタイムというわけですね。


# 深層学習モデルはどのように表現されるのか

深層学習モデルを動作させるためには、それがどのような構造をしているのか知る必要があります。
フレームワークやフォーマットごとに細かい部分は異なりますが、基本的に以下のような特徴を持ちます。

- 有向非巡回グラフ（DAG）
    - ノード: テンソルに対する操作（e.g. Add, Relu, Conv）
    - エッジ: テンソルの値（= データの流れを表現している）
- 入次数が 0 のノードに（入力）テンソルを渡すと、出次数が 0 のノードから（出力）テンソルが得られる
    - ノードは、テンソルを受け取り、それに対して何らかの操作（計算）を行い、テンソルを返す
    - あるノードからあるノードへと行き着くまでに、それぞれのノードの種類に対応する計算が行われる
    - 外から見ると、テンソルを与えたら、別のテンソルが得られるように見える
- DAG であるため、トポロジカルソートするとノードを一列に並べられる
    - 計算機で動かしやすい

また、広く使われているフォーマットとして、[ONNX](https://onnx.ai) が存在します。
ONNX 形式で表現されたモデルを可視化した例を以下に示します。（一番上の `Input3` はノードではなくて入力テンソルの名前、一番下の`Plus214_Output_0` は出力テンソルの名前、それ以外の四角形はノードです）

![mnist](https://cdn.thenewstack.io/media/2020/07/c601845f-onnx-mnist-0-328x1024.jpg)


# 何の言語で実装したのか
  - Rust
  - 実装上の苦労など


# 動作例
