---
title: "深層学習モデルの推論ランタイムを0から作った話"
emoji: "🧮"
type: "idea" # tech: 技術記事 / idea: アイデア
topics: ["onnx", "rust", "深層学習"]
published: false
---

深層学習モデルを動作させるためのソフトウェアは数多くあります。
PyTorch や TensorFlow などのフレームワークはそれ自身がモデルを実行する機能を持っていますし、ONNX Runtime のようにモデルを動作させることに特化したソフトウェアも存在します。

これらのソフトウェアは大抵、Python から簡単に使うことができます。
しかしながら、それらがどのように動作しているのか疑問に思うことはないでしょうか。

この記事では、0 から深層学習モデルの推論ランタイム（長いので以下「深層学習ランタイム」）を作った過程で学んだことを、とりとめもなく紹介していきます。
（技術的にはかなり適当なことを書いてしまうかもしれません。）

- 深層学習ランタイムは何をするのか
  - {モデル, 入力テンソル}→出力テンソル
- 深層学習モデルはどのように表現されるのか
  - 基本的に、有向非巡回グラフ (DAG)
  - ノードはテンソルに対する操作、辺はテンソルの値
  - DAG だから、トポロジカルソートしてやれば一応簡単に逐次実行できる
  - 扱いやすいフォーマットとしてのONNX
- 何の言語で実装したのか
  - Rust
  - 実装上の苦労など
- 動作例
