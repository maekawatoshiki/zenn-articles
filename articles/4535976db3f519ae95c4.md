---
title: "Glow コンパイラを試してみた"
emoji: "💬"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["コンパイラ"]
published: true
---

この記事では、私が [Glow コンパイラ](https://github.com/pytorch/glow) (以下 Glow) をビルドした手順を紹介します。要するに備忘録です。

# Glow とは

世の中には **DNN コンパイラ**と呼ばれるソフトウェアが存在します。DNN コンパイラは、その名の通り Deep Neural Network を入力として受け取り、様々な（ハードウェア非依存・依存の）最適化を施し、特定ハードウェア (CPU, GPU, DSPなど) 向けのコードを出力します。TensorFlow や PyTorch などのフレームワークの背後には DNN コンパイラが隠れているわけですね。

Glow はそんな DNN コンパイラの一つです（もともと Facebook製らしい）。他には [TVM](https://github.com/apache/tvm) などがあります。

# ビルド

さっそく、ビルドしてサンプルなどを動かしてみましょう。

... と行きたいのですが、手元でビルドする中で様々な問題が発生してしまいました（そもそも[ビルドが失敗する](https://github.com/pytorch/glow/issues/5769)、出来上がったバイナリがSEGVを吐いて落ちる、etc...）。
おそらく私が Ubuntu 20.04 を使っているせいなので（Ubuntu 16.04, 18.04 でしかテストされていない）、以下では **Docker** を使ったビルド方法を紹介します。

先に大まかな手順を以下に示しておきます。

1. リポジトリをクローンしておく
2. お好みで Dockerfile をいじる
3. `docker build` & `docker run`
4. ビルド実行

## Dockerfile を用意する

`docker build`したいので Dockerfile が必要ですが、実はすでにリポジトリに用意されています。嬉しいですね。

まずは、[リポジトリ](https://github.com/pytorch/glow)をクローンしておきましょう。次に、`./glow/utils/docker/`に移動して README.md を確認します。
そのまま README.md 通りに実行すればビルドできる（はずな）のですが、このままだと CPU 向けビルドになってしまいます。GPU を使いたい方は、以下のようにファイルを編集する必要があります。

- `./glow/CMakeLists.txt`

  - ```cmake
    ...
    option(GLOW_WITH_OPENCL "Build the OpenCL backend" ON) # OFF から ON に変更
    ...
    ```

- `./glow/utils/docker/Dockerfile`

  - Docker 上で GPU を使うための準備をしておいてください

    - [このあたり](https://qiita.com/ksasaki/items/b20a785e1a0f610efa08)が役に立ちそう

  - ```dockerfile
    FROM nvidia/opencl:devel-ubuntu18.04 # opencl を使うため
    
    ARG WORKDIR=/root/dev
    
    # Create working folder
    RUN mkdir -p $WORKDIR
    WORKDIR $WORKDIR
    
    # Update and install tools
    RUN apt-get update && \
        apt-get install -y clang clang-8 cmake graphviz libpng-dev \
            libprotobuf-dev llvm-8 llvm-8-dev ninja-build protobuf-compiler wget \
            opencl-headers libgoogle-glog-dev libboost-all-dev \
            libdouble-conversion-dev libevent-dev libssl-dev libgflags-dev \
            libjemalloc-dev libpthread-stubs0-dev \
            # Additional dependencies
            git python-numpy && \
        # Delete outdated llvm to avoid conflicts
        apt-get autoremove -y llvm-6.0 && \
        apt-get clean && \
        rm -rf /var/lib/apt/lists/*
    
    # Point clang to llvm-8 version
    RUN update-alternatives --install /usr/bin/clang clang \
            /usr/lib/llvm-8/bin/clang 50 && \
        update-alternatives --install /usr/bin/clang++ clang++ \
            /usr/lib/llvm-8/bin/clang++ 50
    
    # Point default C/C++ compiler to clang
    RUN update-alternatives --set cc /usr/bin/clang && \
        update-alternatives --set c++ /usr/bin/clang++
    
    # Install fmt
    RUN git clone https://github.com/fmtlib/fmt && \
        mkdir fmt/build && \
        cd fmt/build && \
        cmake .. && make -j && \ # 並列ビルド
        make install
    
    # Clean up
    RUN rm -rf fmt
    ```

## Docker でビルドする

以下の通りです。

```sh
pwd
# /PATH/TO/glow/utils/docker
docker build --cpuset-cpus="0-7" -t pytorch/glow . # 適切なCPUコアを指定してください
docker run --cpuset-cpus="0-7" --gpus all -it -v /PATH/TO/glow:/root/dev pytorch/glow
# 以下 Docker 内；Dockerfile に記述してもいいかも？
mkdir build_Release
cd build_Release
cmake -G Ninja -DCMAKE_BUILD_TYPE=Release -DCMAKE_PREFIX_PATH=/usr/lib/llvm-8 ../ # CMAKE_BUILD_TYPE=Debug/Release
ninja all
```

しばらく待ったらビルド終了です。お疲れ様でした。

# MNIST 

サンプルとして用意されている MNIST の学習＆推論を動かしてみます。

```sh
# Docker 内
pwd
# /root/dev/build_Release
python ../utils/download_datasets_and_models.py -d mnist
./bin/mnist --backend $BACKEND # $BACKEND は Interpreter,CPU,OpenCL のどれか
```

`./bin/mnist`で学習が始まり、ちょっとした推論結果がアスキーアートで表示されます。
GPUを使える方はOpenCLを指定すると、CPUよりも高速に学習が進むことを確認できるはずです。（`nvidia-smi`でGPU-Utilが常に90%以上でした）

MNIST 以外のサンプルも用意されているので、詳しくはリポジトリの README.md を参照してください。
